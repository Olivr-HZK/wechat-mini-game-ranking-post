"""
ç”Ÿæˆæ—¥æŠ¥æ¨¡å—
æ ¹æ®æ¸¸æˆåˆ†æç»“æœç”Ÿæˆæ ¼å¼åŒ–çš„æ—¥æŠ¥ï¼ˆJSONæ ¼å¼ï¼‰
"""
from typing import List, Dict
from datetime import datetime
import json
import re


class ReportGenerator:
    """æ—¥æŠ¥ç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ—¥æŠ¥ç”Ÿæˆå™¨"""
        pass
    
    def _clean_markdown(self, text: str) -> str:
        """
        æ¸…ç†Markdownæ ‡ç­¾ï¼Œè½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼
        
        Args:
            text: åŒ…å«Markdownæ ‡ç­¾çš„æ–‡æœ¬
        
        Returns:
            æ¸…ç†åçš„çº¯æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤Markdownæ ‡é¢˜æ ‡è®°
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
        # ç§»é™¤ç²—ä½“æ ‡è®°
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
        text = re.sub(r'__(.+?)__', r'\1', text)
        # ç§»é™¤æ–œä½“æ ‡è®°
        text = re.sub(r'\*(.+?)\*', r'\1', text)
        text = re.sub(r'_(.+?)_', r'\1', text)
        # ç§»é™¤é“¾æ¥æ ‡è®° [text](url) -> text
        text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
        # ç§»é™¤ä»£ç å—æ ‡è®°
        text = re.sub(r'```[\s\S]*?```', '', text)
        text = re.sub(r'`([^`]+)`', r'\1', text)
        # ç§»é™¤åˆ†éš”çº¿
        text = re.sub(r'^---+$', '', text, flags=re.MULTILINE)
        # ç§»é™¤åˆ—è¡¨æ ‡è®°
        text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
        
        return text.strip()
    
    def _extract_core_content(self, analysis_text: str) -> Dict[str, str]:
        """
        ä»åˆ†ææ–‡æœ¬ä¸­æå–æ ¸å¿ƒç©æ³•å’Œå¸å¼•åŠ›
        
        Args:
            analysis_text: åˆ†ææ–‡æœ¬
        
        Returns:
            åŒ…å«core_gameplayå’Œattractionçš„å­—å…¸
        """
        core_gameplay = ""
        attraction = ""
        
        # å°è¯•æå–"æ ¸å¿ƒç©æ³•"éƒ¨åˆ†
        gameplay_patterns = [
            r'æ ¸å¿ƒç©æ³•[ï¼š:]\s*(.+?)(?=\n\n|\n\*\*|$)',
            r'æ ¸å¿ƒç©æ³•æœºåˆ¶[ï¼š:]\s*(.+?)(?=\n\n|\n\*\*|$)',
            r'1[\.ã€]\s*.*?æ ¸å¿ƒç©æ³•[ï¼š:]\s*(.+?)(?=\n\n|\n\d+[\.ã€]|$)',
        ]
        
        for pattern in gameplay_patterns:
            match = re.search(pattern, analysis_text, re.DOTALL | re.IGNORECASE)
            if match:
                core_gameplay = match.group(1).strip()
                break
        
        # å°è¯•æå–"å¸å¼•åŠ›"éƒ¨åˆ†
        attraction_patterns = [
            r'å¸å¼•[ç‚¹åŠ›][ï¼š:]\s*(.+?)(?=\n\n|\n\*\*|$)',
            r'6[\.ã€]\s*.*?å¸å¼•[ç‚¹åŠ›][ï¼š:]\s*(.+?)(?=\n\n|$)',
            r'ä¸ºä»€ä¹ˆ.*?å–œæ¬¢[ï¼š:]\s*(.+?)(?=\n\n|\n\*\*|$)',
        ]
        
        for pattern in attraction_patterns:
            match = re.search(pattern, analysis_text, re.DOTALL | re.IGNORECASE)
            if match:
                attraction = match.group(1).strip()
                break
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŒ‰æ®µè½åˆ†å‰²
        if not core_gameplay or not attraction:
            paragraphs = analysis_text.split('\n\n')
            for para in paragraphs:
                para_clean = para.strip()
                if 'æ ¸å¿ƒç©æ³•' in para_clean or 'ç©æ³•æœºåˆ¶' in para_clean:
                    if not core_gameplay:
                        core_gameplay = self._clean_markdown(para_clean)
                elif 'å¸å¼•' in para_clean or 'å–œæ¬¢' in para_clean:
                    if not attraction:
                        attraction = self._clean_markdown(para_clean)
        
        # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨å‰ä¸¤æ®µä½œä¸ºæ ¸å¿ƒç©æ³•ï¼Œæœ€åä¸€æ®µä½œä¸ºå¸å¼•åŠ›
        if not core_gameplay or not attraction:
            paragraphs = [p.strip() for p in analysis_text.split('\n\n') if p.strip()]
            if paragraphs:
                if not core_gameplay and len(paragraphs) > 0:
                    core_gameplay = self._clean_markdown(paragraphs[0])
                if not attraction and len(paragraphs) > 1:
                    attraction = self._clean_markdown(paragraphs[-1])
        
        return {
            "core_gameplay": self._clean_markdown(core_gameplay) if core_gameplay else "æš‚æ— æ ¸å¿ƒç©æ³•åˆ†æ",
            "attraction": self._clean_markdown(attraction) if attraction else "æš‚æ— å¸å¼•åŠ›åˆ†æ"
        }
    
    def generate_daily_report(self, analyses: List[Dict], date: str = None) -> str:
        """
        ç”Ÿæˆæ—¥æŠ¥å†…å®¹ï¼ˆJSONæ ¼å¼ï¼‰
        
        Args:
            analyses: æ¸¸æˆåˆ†æç»“æœåˆ—è¡¨
            date: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
        Returns:
            JSONæ ¼å¼çš„æ—¥æŠ¥å†…å®¹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        """
        if not date:
            date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        # æ„å»ºJSONç»“æ„
        report_data = {
            "report_type": "å°æ¸¸æˆçƒ­æ¦œç©æ³•è§£ææ—¥æŠ¥",
            "date": date,
            "game_count": len(analyses),
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "games": []
        }
        
        # å¤„ç†æ¯ä¸ªæ¸¸æˆçš„åˆ†æ
        for idx, analysis in enumerate(analyses, 1):
            game_name = analysis.get("game_name", "æœªçŸ¥æ¸¸æˆ")
            analysis_text = analysis.get("analysis", "æš‚æ— åˆ†æå†…å®¹")
            analysis_data = analysis.get("analysis_data")  # ç»“æ„åŒ–çš„JSONæ•°æ®
            model_used = analysis.get("model_used", "unknown")
            status = analysis.get("status", "unknown")
            
            # å¦‚æœæœ‰å…³é”®è¯æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™ä»æ–‡æœ¬ä¸­æå–
            if analysis_data and isinstance(analysis_data, dict):
                # ä½¿ç”¨ç»“æ„åŒ–çš„JSONæ•°æ®
                core_gameplay_data = analysis_data.get("core_gameplay", {})
                attraction_data = analysis_data.get("attraction", {})  # å…¼å®¹æ—§æ ¼å¼ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
                genre_baseline_data = analysis_data.get("genre_baseline", {})
                innovation_data = analysis_data.get("innovation", {})
                baseline_innovation_data = analysis_data.get("baseline_and_innovation", {})
                
                # æ„å»ºæ ¸å¿ƒç©æ³•æ–‡æœ¬ï¼ˆåˆå¹¶æ‰€æœ‰å­—æ®µï¼‰
                core_gameplay_parts = []
                if core_gameplay_data.get("mechanism"):
                    core_gameplay_parts.append(f"ç©æ³•æœºåˆ¶ï¼š{core_gameplay_data['mechanism']}")
                if core_gameplay_data.get("operation"):
                    core_gameplay_parts.append(f"æ“ä½œæ–¹å¼ï¼š{core_gameplay_data['operation']}")
                if core_gameplay_data.get("rules"):
                    core_gameplay_parts.append(f"æ¸¸æˆè§„åˆ™ï¼š{core_gameplay_data['rules']}")
                if core_gameplay_data.get("features"):
                    core_gameplay_parts.append(f"ç‰¹è‰²åŠŸèƒ½ï¼š{core_gameplay_data['features']}")
                
                core_gameplay = "\n\n".join(core_gameplay_parts) if core_gameplay_parts else "æš‚æ— æ ¸å¿ƒç©æ³•åˆ†æ"
                
                # æ„å»ºå¸å¼•åŠ›æ–‡æœ¬ï¼ˆåˆå¹¶æ‰€æœ‰å­—æ®µï¼‰
                attraction_parts = []
                if attraction_data.get("points"):
                    attraction_parts.append(f"å¸å¼•ç‚¹ï¼š{attraction_data['points']}")
                if attraction_data.get("target_audience"):
                    attraction_parts.append(f"ç›®æ ‡ç”¨æˆ·ï¼š{attraction_data['target_audience']}")
                if attraction_data.get("retention_factors"):
                    attraction_parts.append(f"ç•™å­˜å› ç´ ï¼š{attraction_data['retention_factors']}")
                
                attraction = "\n\n".join(attraction_parts) if attraction_parts else "æš‚æ— å¸å¼•åŠ›åˆ†æ"

                # æ„å»ºå“ç±»åŸºçº¿ + åˆ›æ–°ç‚¹ï¼ˆæ–°æ ¼å¼ï¼Œå…¼å®¹ä¸¤ç§schemaï¼‰
                genre_baseline_parts = []
                # schema A: genre_baseline
                if isinstance(genre_baseline_data, dict):
                    if genre_baseline_data.get("base_genre"):
                        genre_baseline_parts.append(f"åŸºç±»å“ç±»ï¼š{genre_baseline_data['base_genre']}")
                    if genre_baseline_data.get("reference"):
                        genre_baseline_parts.append(f"å‚è€ƒèŒƒå¼ï¼š{genre_baseline_data['reference']}")
                    if genre_baseline_data.get("baseline_loop"):
                        genre_baseline_parts.append(f"å“ç±»åŸºçº¿å¾ªç¯ï¼š{genre_baseline_data['baseline_loop']}")
                # schema B: baseline_and_innovation
                if isinstance(baseline_innovation_data, dict):
                    if baseline_innovation_data.get("base_genre") and not any("åŸºç±»å“ç±»ï¼š" in x for x in genre_baseline_parts):
                        genre_baseline_parts.append(f"åŸºç±»å“ç±»ï¼š{baseline_innovation_data['base_genre']}")
                    if baseline_innovation_data.get("baseline_loop") and not any("å“ç±»åŸºçº¿å¾ªç¯ï¼š" in x for x in genre_baseline_parts):
                        genre_baseline_parts.append(f"å“ç±»åŸºçº¿å¾ªç¯ï¼š{baseline_innovation_data['baseline_loop']}")
                genre_baseline = "\n\n".join(genre_baseline_parts).strip()

                innovation_parts = []
                # schema A: innovation
                if isinstance(innovation_data, dict):
                    if innovation_data.get("summary"):
                        innovation_parts.append(f"åˆ›æ–°æ€»ç»“ï¼š{innovation_data['summary']}")
                    pts = innovation_data.get("innovation_points")
                    if isinstance(pts, list) and pts:
                        innovation_parts.append("åˆ›æ–°ç‚¹ï¼š\n" + "\n".join([f"- {str(x).strip()}" for x in pts if str(x).strip()]))
                    if innovation_data.get("how_it_changes_play"):
                        innovation_parts.append(f"å¦‚ä½•æ”¹å˜ç©æ³•ï¼š{innovation_data['how_it_changes_play']}")
                    ev = innovation_data.get("evidence_from_video")
                    if isinstance(ev, list) and ev:
                        innovation_parts.append("è§†é¢‘è¯æ®ï¼š\n" + "\n".join([f"- {str(x).strip()}" for x in ev if str(x).strip()]))
                    if innovation_data.get("tradeoffs"):
                        innovation_parts.append(f"ä»£ä»·/é£é™©ï¼š{innovation_data['tradeoffs']}")
                # schema B: baseline_and_innovationï¼ˆä¸¤æ®µå¼ï¼šå¾®è°ƒåˆ›æ–°ï¼‰
                if isinstance(baseline_innovation_data, dict):
                    pts2 = baseline_innovation_data.get("micro_innovations")
                    if isinstance(pts2, list) and pts2:
                        innovation_parts.append("å¾®è°ƒåˆ›æ–°ç‚¹ï¼š\n" + "\n".join([f"- {str(x).strip()}" for x in pts2 if str(x).strip()]))
                innovation = "\n\n".join([p for p in innovation_parts if p.strip()]).strip()
            else:
                # ä»æ–‡æœ¬ä¸­æå–ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                content = self._extract_core_content(analysis_text)
                core_gameplay = content["core_gameplay"]
                attraction = content["attraction"]
                genre_baseline = ""
                innovation = ""
            
            game_data = {
                "index": idx,
                "game_name": game_name,
                "game_rank": analysis.get("game_rank", ""),  # æ¸¸æˆæ’å
                "game_company": analysis.get("game_company", ""),  # å¼€å‘å…¬å¸
                "rank_change": analysis.get("rank_change", "--"),  # æ’åå˜åŒ–
                "monitor_date": analysis.get("monitor_date", ""),  # ç›‘æ§æ—¥æœŸ YYYY-MM-DD
                "platform": analysis.get("platform", ""),  # vx / dy
                "source": analysis.get("source", ""),  # æ¦œå•
                "board_name": analysis.get("board_name", ""),  # æ¦œå•åç§°
                "gdrive_url": analysis.get("gdrive_url", ""),  # Google Driveè§†é¢‘é“¾æ¥
                "core_gameplay": core_gameplay,
                "attraction": attraction,
                "genre_baseline": genre_baseline,
                "innovation": innovation,
                "analysis_data": analysis_data,  # ä¿ç•™ç»“æ„åŒ–æ•°æ®
                "full_analysis": analysis_text,  # ä¿ç•™å®Œæ•´åˆ†ææ–‡æœ¬
                "analysis_model": model_used,
                "analysis_status": status
            }
            
            report_data["games"].append(game_data)
        
        # æ·»åŠ æ€»ç»“
        report_data["summary"] = {
            "total_games": len(analyses),
            "description": f"æœ¬æ¬¡æ—¥æŠ¥åˆ†æäº†çƒ­æ¦œä¸Šçš„ {len(analyses)} æ¬¾æ¸¸æˆï¼Œæ¶µç›–äº†å¤šç§æ¸¸æˆç±»å‹ã€‚è¿™äº›æ¸¸æˆéƒ½å…·æœ‰ç®€å•æ˜“ä¸Šæ‰‹çš„ç‰¹ç‚¹ï¼Œé€‚åˆç¢ç‰‡åŒ–æ—¶é—´æ¸¸ç©ã€‚å»ºè®®å…³æ³¨æ¸¸æˆçš„æ ¸å¿ƒç©æ³•æœºåˆ¶å’Œç”¨æˆ·ç•™å­˜ç­–ç•¥ã€‚"
        }
        
        # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼ˆæ ¼å¼åŒ–è¾“å‡ºï¼Œä¾¿äºé˜…è¯»ï¼‰
        return json.dumps(report_data, ensure_ascii=False, indent=2)
    
    def generate_feishu_format(self, analyses: List[Dict], date: str = None) -> Dict:
        """
        ç”Ÿæˆé£ä¹¦æ ¼å¼çš„æ—¥æŠ¥å†…å®¹ï¼ˆJSONæ ¼å¼ï¼‰
        
        Args:
            analyses: æ¸¸æˆåˆ†æç»“æœåˆ—è¡¨
            date: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
        Returns:
            é£ä¹¦æ¶ˆæ¯æ ¼å¼çš„å­—å…¸ï¼ˆJSONæ ¼å¼ï¼‰
        """
        if not date:
            date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        # æ„å»ºç»“æ„åŒ–å†…å®¹
        elements = []
        
        # æ ‡é¢˜å’Œæ‘˜è¦
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": f"**ğŸ“… æ—¥æœŸï¼š** {date}\n**ğŸ® åˆ†ææ¸¸æˆæ•°é‡ï¼š** {len(analyses)}"
            }
        })
        
        elements.append({"tag": "hr"})
        
        # æ¯ä¸ªæ¸¸æˆçš„åˆ†æ
        for idx, analysis in enumerate(analyses, 1):
            game_name = analysis.get("game_name", "æœªçŸ¥æ¸¸æˆ")
            analysis_text = analysis.get("analysis", "æš‚æ— åˆ†æå†…å®¹")
            analysis_data = analysis.get("analysis_data")  # ç»“æ„åŒ–çš„JSONæ•°æ®
            
            # å¦‚æœæœ‰å…³é”®è¯æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™ä»æ–‡æœ¬ä¸­æå–
            if analysis_data and isinstance(analysis_data, dict):
                core_gameplay_data = analysis_data.get("core_gameplay", {})
                attraction_data = analysis_data.get("attraction", {})  # å…¼å®¹æ—§æ ¼å¼ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
                genre_baseline_data = analysis_data.get("genre_baseline", {})
                innovation_data = analysis_data.get("innovation", {})
                baseline_innovation_data = analysis_data.get("baseline_and_innovation", {})
                
                # æ„å»ºæ ¸å¿ƒç©æ³•æ–‡æœ¬
                core_gameplay_parts = []
                if core_gameplay_data.get("mechanism"):
                    core_gameplay_parts.append(f"**ç©æ³•æœºåˆ¶ï¼š** {core_gameplay_data['mechanism']}")
                if core_gameplay_data.get("operation"):
                    core_gameplay_parts.append(f"**æ“ä½œæ–¹å¼ï¼š** {core_gameplay_data['operation']}")
                if core_gameplay_data.get("rules"):
                    core_gameplay_parts.append(f"**æ¸¸æˆè§„åˆ™ï¼š** {core_gameplay_data['rules']}")
                if core_gameplay_data.get("features"):
                    core_gameplay_parts.append(f"**ç‰¹è‰²åŠŸèƒ½ï¼š** {core_gameplay_data['features']}")
                
                core_gameplay = "\n\n".join(core_gameplay_parts) if core_gameplay_parts else "æš‚æ— æ ¸å¿ƒç©æ³•åˆ†æ"
                
                # æ„å»ºå¸å¼•åŠ›æ–‡æœ¬
                attraction_parts = []
                if attraction_data.get("points"):
                    attraction_parts.append(f"**å¸å¼•ç‚¹ï¼š** {attraction_data['points']}")
                if attraction_data.get("target_audience"):
                    attraction_parts.append(f"**ç›®æ ‡ç”¨æˆ·ï¼š** {attraction_data['target_audience']}")
                if attraction_data.get("retention_factors"):
                    attraction_parts.append(f"**ç•™å­˜å› ç´ ï¼š** {attraction_data['retention_factors']}")
                
                attraction = "\n\n".join(attraction_parts) if attraction_parts else "æš‚æ— å¸å¼•åŠ›åˆ†æ"
            else:
                # ä»æ–‡æœ¬ä¸­æå–ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                content = self._extract_core_content(analysis_text)
                core_gameplay = content["core_gameplay"]
                attraction = content["attraction"]
                genre_baseline_data = {}
                innovation_data = {}
            
            # æ¸¸æˆæ ‡é¢˜å’Œä¿¡æ¯
            game_rank = analysis.get("game_rank", "")
            game_company = analysis.get("game_company", "")
            rank_change = analysis.get("rank_change", "--")
            # è§†é¢‘é“¾æ¥ï¼šä¼˜å…ˆè·³å›æŠ–éŸ³åˆ†äº«é“¾æ¥ï¼ˆshare_urlï¼‰ï¼Œå¦åˆ™å…œåº•ç”¨ gdrive_url
            share_url = analysis.get("share_url", "")
            gdrive_url = analysis.get("gdrive_url", "")
            monitor_date = analysis.get("monitor_date", "")
            platform = analysis.get("platform", "")
            source = analysis.get("source", "")
            board_name = analysis.get("board_name", "")
            
            def _ok(v: str) -> bool:
                return bool(v and str(v).strip() and str(v).strip() not in {"--", "N/A", "None"})

            # æ„å»ºæ¸¸æˆä¿¡æ¯æ ‡é¢˜ï¼ˆå¤šè¡Œ + å›¾æ ‡ + åŠ ç²—æ ‡ç­¾ï¼Œå¢å¼ºå¯è¯»æ€§ï¼‰
            title_lines = [f"**ã€æ¸¸æˆ {idx}ã€‘{game_name}**"]
            if _ok(game_rank):
                title_lines.append(f"**ğŸ… æ’åï¼š** {game_rank}")
            if _ok(game_company):
                title_lines.append(f"**ğŸ¢ å¼€å‘å…¬å¸ï¼š** {game_company}")
            if _ok(platform):
                title_lines.append(f"**ğŸ“± å¹³å°ï¼š** {platform}")
            if _ok(source):
                title_lines.append(f"**ğŸ§­ æ¥æºï¼š** {source}")
            if _ok(board_name):
                title_lines.append(f"**ğŸ·ï¸ æ¦œå•ï¼š** {board_name}")
            if _ok(monitor_date):
                title_lines.append(f"**ğŸ—“ï¸ ç›‘æ§æ—¥æœŸï¼š** {monitor_date}")
            if _ok(rank_change) and str(rank_change).strip() != "--":
                title_lines.append(f"**ğŸ“ˆ æ’åå˜åŒ–ï¼š** {rank_change}")
            video_link = share_url if _ok(share_url) else gdrive_url
            if _ok(video_link):
                title_lines.append(f"**ğŸ”— è§†é¢‘é“¾æ¥ï¼š** [ç‚¹å‡»æŸ¥çœ‹]({video_link})")
            
            elements.append({
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": "\n".join(title_lines)
                }
            })
            
            # æ ¸å¿ƒç©æ³• - åˆ†æ®µæ˜¾ç¤ºï¼Œé¿å…å†…å®¹è¿‡é•¿
            if core_gameplay and core_gameplay != "æš‚æ— æ ¸å¿ƒç©æ³•åˆ†æ":
                # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œå¯èƒ½éœ€è¦åˆ†æ®µ
                # é£ä¹¦å•ä¸ªå…ƒç´ å»ºè®®ä¸è¶…è¿‡2000å­—ç¬¦
                if len(core_gameplay) > 1800:
                    # åˆ†æ®µæ˜¾ç¤º
                    gameplay_lines = core_gameplay.split("\n\n")
                    current_section = ""
                    for line in gameplay_lines:
                        if len(current_section) + len(line) > 1800:
                            if current_section:
                                elements.append({
                                    "tag": "div",
                                    "text": {
                                        "tag": "lark_md",
                                        "content": f"**ğŸ“‹ æ ¸å¿ƒç©æ³•è§£æï¼ˆç»­ï¼‰ï¼š**\n{current_section}"
                                    }
                                })
                            current_section = line
                        else:
                            current_section += "\n\n" + line if current_section else line
                    if current_section:
                        elements.append({
                            "tag": "div",
                            "text": {
                                "tag": "lark_md",
                                "content": f"**ğŸ“‹ æ ¸å¿ƒç©æ³•è§£æ{'ï¼ˆç»­ï¼‰' if len(core_gameplay) > 1800 else ''}ï¼š**\n{current_section}"
                            }
                        })
                else:
                    elements.append({
                        "tag": "div",
                        "text": {
                            "tag": "lark_md",
                            "content": f"**ğŸ“‹ æ ¸å¿ƒç©æ³•è§£æï¼š**\n{core_gameplay}"
                        }
                    })

            # å“ç±»åŸºçº¿ï¼ˆæ–°æç¤ºè¯ï¼‰
            if isinstance(genre_baseline_data, dict) and any(
                genre_baseline_data.get(k) for k in ["base_genre", "reference", "baseline_loop"]
            ):
                base_genre = genre_baseline_data.get("base_genre") or ""
                reference = genre_baseline_data.get("reference") or ""
                baseline_loop = genre_baseline_data.get("baseline_loop") or ""

                gb_lines = []
                if base_genre:
                    gb_lines.append(f"**åŸºç±»å“ç±»ï¼š** {base_genre}")
                if reference:
                    gb_lines.append(f"**å‚è€ƒèŒƒå¼ï¼š** {reference}")
                if baseline_loop:
                    gb_lines.append(f"**å“ç±»åŸºçº¿å¾ªç¯ï¼š** {baseline_loop}")

                elements.append({
                    "tag": "div",
                    "text": {
                        "tag": "lark_md",
                        "content": "**ğŸ§© å“ç±»åŸºçº¿ï¼š**\n" + "\n".join(gb_lines)
                    }
                })

            # åˆ›æ–°ç‚¹åˆ†æï¼ˆæ–°æç¤ºè¯ï¼‰
            if isinstance(innovation_data, dict) and any(
                innovation_data.get(k) for k in ["summary", "innovation_points", "how_it_changes_play", "evidence_from_video", "tradeoffs"]
            ):
                inv_lines = []
                if innovation_data.get("summary"):
                    inv_lines.append(f"**åˆ›æ–°æ€»ç»“ï¼š** {innovation_data['summary']}")
                pts = innovation_data.get("innovation_points")
                if isinstance(pts, list) and pts:
                    bullets = "\n".join([f"- {str(x).strip()}" for x in pts if str(x).strip()])
                    if bullets:
                        inv_lines.append("**åˆ›æ–°ç‚¹ï¼š**\n" + bullets)
                if innovation_data.get("how_it_changes_play"):
                    inv_lines.append(f"**å¦‚ä½•æ”¹å˜ç©æ³•ï¼š** {innovation_data['how_it_changes_play']}")
                ev = innovation_data.get("evidence_from_video")
                if isinstance(ev, list) and ev:
                    eb = "\n".join([f"- {str(x).strip()}" for x in ev if str(x).strip()])
                    if eb:
                        inv_lines.append("**è§†é¢‘è¯æ®ï¼š**\n" + eb)
                if innovation_data.get("tradeoffs"):
                    inv_lines.append(f"**ä»£ä»·/é£é™©ï¼š** {innovation_data['tradeoffs']}")

                inv_text = "\n\n".join([x for x in inv_lines if x.strip()]).strip()
                if inv_text:
                    # åŒæ ·æ§åˆ¶å•æ®µé•¿åº¦ï¼Œé¿å…è¶… 2000
                    if len(inv_text) > 1800:
                        chunks = []
                        buf = ""
                        for block in inv_text.split("\n\n"):
                            block = block.strip()
                            if not block:
                                continue
                            candidate = block if not buf else (buf + "\n\n" + block)
                            if len(candidate) <= 1800:
                                buf = candidate
                                continue
                            if buf:
                                chunks.append(buf)
                                buf = ""
                            while len(block) > 1800:
                                chunks.append(block[:1800])
                                block = block[1800:]
                            buf = block
                        if buf:
                            chunks.append(buf)

                        for ci, c in enumerate(chunks, 1):
                            elements.append({
                                "tag": "div",
                                "text": {
                                    "tag": "lark_md",
                                    "content": f"**ğŸ’¡ åˆ›æ–°ç‚¹åˆ†æ{'ï¼ˆç»­ï¼‰' if ci > 1 else ''}ï¼š**\n{c}"
                                }
                            })
                    else:
                        elements.append({
                            "tag": "div",
                            "text": {
                                "tag": "lark_md",
                                "content": f"**ğŸ’¡ åˆ›æ–°ç‚¹åˆ†æï¼š**\n{inv_text}"
                            }
                        })

            # ä¸¤æ®µå¼ï¼šåŸºçº¿ + å¾®è°ƒåˆ›æ–°ï¼ˆbaseline_and_innovationï¼‰
            if isinstance(baseline_innovation_data, dict) and any(
                baseline_innovation_data.get(k) for k in ["base_genre", "baseline_loop", "micro_innovations"]
            ):
                bi_lines = []
                if baseline_innovation_data.get("base_genre"):
                    bi_lines.append(f"**åŸºçº¿å“ç±»ï¼š** {baseline_innovation_data['base_genre']}")
                if baseline_innovation_data.get("baseline_loop"):
                    bi_lines.append(f"**åŸºçº¿å¾ªç¯ï¼š** {baseline_innovation_data['baseline_loop']}")
                pts2 = baseline_innovation_data.get("micro_innovations")
                if isinstance(pts2, list) and pts2:
                    bullets = "\n".join([f"- {str(x).strip()}" for x in pts2 if str(x).strip()])
                    if bullets:
                        bi_lines.append("**å¾®è°ƒåˆ›æ–°ç‚¹ï¼š**\n" + bullets)

                bi_text = "\n\n".join([x for x in bi_lines if x.strip()]).strip()
                if bi_text:
                    elements.append({
                        "tag": "div",
                        "text": {
                            "tag": "lark_md",
                            "content": f"**ğŸ§± åŸºçº¿ä¸å¾®è°ƒåˆ›æ–°ï¼š**\n{bi_text}"
                        }
                    })
            
            # æ·»åŠ æ¸¸æˆæˆªå›¾ï¼ˆæ”¯æŒå¤šå¼ ï¼‰- æ”¾åœ¨ç©æ³•æ‹†è§£ä¸‹é¢
            screenshot_keys = analysis.get("screenshot_image_keys")
            if not screenshot_keys:
                # å…¼å®¹æ—§æ ¼å¼ï¼šå•ä¸ªscreenshot_image_key
                screenshot_key = analysis.get("screenshot_image_key")
                if screenshot_key:
                    screenshot_keys = [screenshot_key]
            
            if screenshot_keys:
                # æ·»åŠ æˆªå›¾æ ‡é¢˜
                elements.append({
                    "tag": "div",
                    "text": {
                        "tag": "lark_md",
                        "content": "**ğŸ¬ æ¸¸æˆæˆªå›¾ï¼š**"
                    }
                })
                
                # å‚ç›´æ’åˆ—æ‰€æœ‰æˆªå›¾ï¼Œæ¯å¼ å›¾ç‰‡éƒ½æœ‰æ ‡ç­¾
                screenshot_labels = ["å¼€å¤´", "ä¸­é—´", "ç»“å°¾"]
                for img_idx, screenshot_key in enumerate(screenshot_keys):
                    label = screenshot_labels[img_idx] if img_idx < len(screenshot_labels) else f"æˆªå›¾{img_idx+1}"
                    # æ·»åŠ æ ‡ç­¾
                    elements.append({
                        "tag": "div",
                        "text": {
                            "tag": "lark_md",
                            "content": f"*{label}æˆªå›¾*"
                        }
                    })
                    # æ·»åŠ å›¾ç‰‡ï¼ˆé£ä¹¦ä¼šè‡ªåŠ¨è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥é€‚åº”å¡ç‰‡å®½åº¦ï¼‰
                    elements.append({
                        "tag": "img",
                        "img_key": screenshot_key,
                        "alt": {
                            "tag": "plain_text",
                            "content": f"{game_name}{label}æˆªå›¾"
                        }
                    })
            
            # å¸å¼•åŠ›åˆ†æ - åˆ†æ®µæ˜¾ç¤ºï¼Œé¿å…å†…å®¹è¿‡é•¿
            if attraction and attraction != "æš‚æ— å¸å¼•åŠ›åˆ†æ":
                if len(attraction) > 1800:
                    # åˆ†æ®µæ˜¾ç¤º
                    attraction_lines = attraction.split("\n\n")
                    current_section = ""
                    for line in attraction_lines:
                        if len(current_section) + len(line) > 1800:
                            if current_section:
                                elements.append({
                                    "tag": "div",
                                    "text": {
                                        "tag": "lark_md",
                                        "content": f"**â­ å¸å¼•åŠ›åˆ†æï¼ˆç»­ï¼‰ï¼š**\n{current_section}"
                                    }
                                })
                            current_section = line
                        else:
                            current_section += "\n\n" + line if current_section else line
                    if current_section:
                        elements.append({
                            "tag": "div",
                            "text": {
                                "tag": "lark_md",
                                "content": f"**â­ å¸å¼•åŠ›åˆ†æ{'ï¼ˆç»­ï¼‰' if len(attraction) > 1800 else ''}ï¼š**\n{current_section}"
                            }
                        })
                else:
                    elements.append({
                        "tag": "div",
                        "text": {
                            "tag": "lark_md",
                            "content": f"**â­ å¸å¼•åŠ›åˆ†æï¼š**\n{attraction}"
                        }
                    })
            
            if idx < len(analyses):
                elements.append({"tag": "hr"})
        
        # æ€»ç»“
        elements.append({"tag": "hr"})
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": f"**ğŸ“Š æ€»ç»“**\n\næœ¬æ¬¡æ—¥æŠ¥åˆ†æäº†çƒ­æ¦œä¸Šçš„ {len(analyses)} æ¬¾æ¸¸æˆï¼Œæ¶µç›–äº†å¤šç§æ¸¸æˆç±»å‹ã€‚è¿™äº›æ¸¸æˆéƒ½å…·æœ‰ç®€å•æ˜“ä¸Šæ‰‹çš„ç‰¹ç‚¹ï¼Œé€‚åˆç¢ç‰‡åŒ–æ—¶é—´æ¸¸ç©ã€‚"
            }
        })
        
        # æ·»åŠ JSONæ ¼å¼çš„åŸå§‹æ•°æ®ï¼ˆä½œä¸ºé™„ä»¶æˆ–é¢å¤–ä¿¡æ¯ï¼‰
        # ç”ŸæˆJSONæ ¼å¼çš„æŠ¥å‘Šæ•°æ®
        report_json = self.generate_daily_report(analyses, date)
        
        # æ„å»ºé£ä¹¦æ¶ˆæ¯å¡ç‰‡
        feishu_message = {
            "msg_type": "interactive",
            "card": {
                "config": {
                    "wide_screen_mode": True
                },
                "header": {
                    "title": {
                        "tag": "plain_text",
                        "content": f"ğŸ® å°æ¸¸æˆçƒ­æ¦œç©æ³•è§£ææ—¥æŠ¥ - {date}"
                    },
                    "template": "blue"
                },
                "elements": elements
            }
        }
        
        return feishu_message
    
    def _simplify_analysis(self, analysis_text: str, max_length: int = 1000) -> str:
        """
        ç®€åŒ–åˆ†ææ–‡æœ¬ï¼Œé€‚åº”é£ä¹¦æ¶ˆæ¯é•¿åº¦é™åˆ¶
        
        Args:
            analysis_text: åŸå§‹åˆ†ææ–‡æœ¬
            max_length: æœ€å¤§é•¿åº¦
        
        Returns:
            ç®€åŒ–åçš„æ–‡æœ¬
        """
        if len(analysis_text) <= max_length:
            return analysis_text
        
        # æå–å…³é”®éƒ¨åˆ†
        lines = analysis_text.split('\n')
        simplified = []
        current_length = 0
        
        for line in lines:
            if current_length + len(line) > max_length:
                break
            simplified.append(line)
            current_length += len(line) + 1
        
        result = '\n'.join(simplified)
        if len(result) < len(analysis_text):
            result += "\n\n...ï¼ˆå†…å®¹å·²æˆªæ–­ï¼‰"
        
        return result